{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage.feature import hog, local_binary_pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Path Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path dataset lokal\n",
    "train_folder = 'dataset/final_dataset/train'\n",
    "test_folder = 'dataset/final_dataset/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ekstrasi Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The input image is too small given the values of pixels_per_cell and cells_per_block. It should have at least: 16 rows and 16 cols.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 96\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(features), np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Ekstraksi fitur train dan test\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m extract_features(train_df)\n\u001b[0;32m     97\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m extract_features(test_df)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Standarisasi fitur\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 90\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(data_df)\u001b[0m\n\u001b[0;32m     88\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m data_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 90\u001b[0m     img_features \u001b[38;5;241m=\u001b[39m extract_features_from_image(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilepath\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     91\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(img_features)\n\u001b[0;32m     92\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[15], line 77\u001b[0m, in \u001b[0;36mextract_features_from_image\u001b[1;34m(img_path, size, grid_size)\u001b[0m\n\u001b[0;32m     74\u001b[0m     section \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(section, (\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m16\u001b[39m))\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Ekstraksi fitur HOG untuk tiap grid\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m hog_features \u001b[38;5;241m=\u001b[39m extract_hog_features(section, size\u001b[38;5;241m=\u001b[39m(grid_size, grid_size))\n\u001b[0;32m     78\u001b[0m features\u001b[38;5;241m.\u001b[39mextend(hog_features)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Ekstraksi fitur LBP untuk tiap grid\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 23\u001b[0m, in \u001b[0;36mextract_hog_features\u001b[1;34m(img, size)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Check if the image is grayscale (single channel)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(img_resized\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:  \u001b[38;5;66;03m# Grayscale image\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     features, _ \u001b[38;5;241m=\u001b[39m hog(\n\u001b[0;32m     24\u001b[0m         img_resized,\n\u001b[0;32m     25\u001b[0m         orientations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m,\n\u001b[0;32m     26\u001b[0m         pixels_per_cell\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m),\n\u001b[0;32m     27\u001b[0m         cells_per_block\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m     28\u001b[0m         block_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL2-Hys\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     29\u001b[0m         visualize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     features, _ \u001b[38;5;241m=\u001b[39m hog(\n\u001b[0;32m     33\u001b[0m         img_resized,\n\u001b[0;32m     34\u001b[0m         orientations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m         multichannel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Use multichannel for color images\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\skimage\\_shared\\utils.py:438\u001b[0m, in \u001b[0;36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    435\u001b[0m channel_axis \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannel_axis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m channel_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;66;03m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;66;03m#       supporting a tuple of channel axes. Right now, only an\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;66;03m#       integer or a single-element tuple is supported, though.\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(channel_axis):\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\skimage\\feature\\_hog.py:314\u001b[0m, in \u001b[0;36mhog\u001b[1;34m(image, orientations, pixels_per_cell, cells_per_block, block_norm, visualize, transform_sqrt, feature_vector, channel_axis)\u001b[0m\n\u001b[0;32m    312\u001b[0m     min_row \u001b[38;5;241m=\u001b[39m b_row \u001b[38;5;241m*\u001b[39m c_row\n\u001b[0;32m    313\u001b[0m     min_col \u001b[38;5;241m=\u001b[39m b_col \u001b[38;5;241m*\u001b[39m c_col\n\u001b[1;32m--> 314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe input image is too small given the values of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    316\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixels_per_cell and cells_per_block. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    317\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIt should have at least: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_row\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cols.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    319\u001b[0m     )\n\u001b[0;32m    320\u001b[0m normalized_blocks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m    321\u001b[0m     (n_blocks_row, n_blocks_col, b_row, b_col, orientations), dtype\u001b[38;5;241m=\u001b[39mfloat_dtype\n\u001b[0;32m    322\u001b[0m )\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_blocks_row):\n",
      "\u001b[1;31mValueError\u001b[0m: The input image is too small given the values of pixels_per_cell and cells_per_block. It should have at least: 16 rows and 16 cols."
     ]
    }
   ],
   "source": [
    "# Fungsi untuk mendapatkan target label berdasarkan struktur folder\n",
    "def load_images_and_labels(folder_path):\n",
    "    data = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                # Ekstrak label dari angka sebelum ekstensi\n",
    "                label = int(file_name.split('_')[-1].split('.')[0])\n",
    "                data.append((file_path, label))  # Path dan label\n",
    "    return pd.DataFrame(data, columns=['filepath', 'label'])\n",
    "\n",
    "# Load data train dan test\n",
    "train_df = load_images_and_labels(train_folder)\n",
    "test_df = load_images_and_labels(test_folder)\n",
    "\n",
    "# Ekstrak fitur HOG\n",
    "def extract_hog_features(img, size=(200, 200)):\n",
    "    img_resized = cv2.resize(img, size)\n",
    "    features, _ = hog(\n",
    "        img_resized,\n",
    "        orientations=9,\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(2, 2),\n",
    "        block_norm='L2-Hys',\n",
    "        visualize=True,\n",
    "        multichannel=False\n",
    "    )\n",
    "    return features\n",
    "\n",
    "# Ekstraksi fitur LBP\n",
    "def extract_lbp_features(img, size=(200, 200)):\n",
    "    img_resized = cv2.resize(img, size)\n",
    "    radius = 1\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(img_resized, n_points, radius, method='uniform')\n",
    "    # Hitung histogram LBP\n",
    "    (hist, _) = np.histogram(\n",
    "        lbp.ravel(),\n",
    "        bins=np.arange(0, n_points + 3),\n",
    "        range=(0, n_points + 2)\n",
    "    )\n",
    "    # Normalisasi histogram\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "    return hist\n",
    "\n",
    "# Fungsi untuk ekstraksi fitur dari gambar menggunakan grid 10x10\n",
    "def extract_features_from_image(img_path, size=(200, 200), grid_size=10):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, size)\n",
    "    \n",
    "    features = []\n",
    "    for y in range(0, size[0], grid_size):\n",
    "        for x in range(0, size[1], grid_size):\n",
    "            # Potong gambar sesuai grid\n",
    "            section = img[y:y+grid_size, x:x+grid_size]\n",
    "            # Ekstraksi fitur HOG untuk tiap grid\n",
    "            hog_features = extract_hog_features(section, size=(grid_size, grid_size))\n",
    "            features.extend(hog_features)\n",
    "            # Ekstraksi fitur LBP untuk tiap grid\n",
    "            lbp_features = extract_lbp_features(section, size=(grid_size, grid_size))\n",
    "            features.extend(lbp_features)\n",
    "    return np.array(features)\n",
    "\n",
    "# Ekstraksi fitur dari dataset\n",
    "def extract_features(data_df):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for _, row in data_df.iterrows():\n",
    "        img_features = extract_features_from_image(row['filepath'])\n",
    "        features.append(img_features)\n",
    "        labels.append(row['label'])\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Ekstraksi fitur train dan test\n",
    "X_train, y_train = extract_features(train_folder)\n",
    "X_test, y_test = extract_features(test_folder)\n",
    "\n",
    "# Standarisasi fitur\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasifikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[459  23  11   5   3   9]\n",
      " [ 19 379  59  36   6  11]\n",
      " [ 14  61 286  95  39  15]\n",
      " [  2  35 135 215  93  30]\n",
      " [  8   8  31  95 297  71]\n",
      " [  1  10  24  39  51 385]]\n",
      "Accuracy: 66.05%\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Membuat model XGBoost\n",
    "xgb_model = XGBClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "# Melatih model\n",
    "xgb_model.fit(X_train_sc, y_train)\n",
    "\n",
    "# Evaluasi model\n",
    "y_pred = xgb_model.predict(X_test_sc)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Akurasi Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving the XGBoost model from above in a pickle file for possible use later.\n",
    "xgb_pickle = f\"model/xgboost_hog_lbp_model_acc_{accuracy}.pkl\"\n",
    "with open(xgb_pickle, 'wb') as file:\n",
    "    pickle.dump(xgb_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[459  37   2   3   4   5]\n",
      " [ 45 376  63  16   3   7]\n",
      " [ 21  98 231 105  38  17]\n",
      " [ 19  52 138 184  87  30]\n",
      " [  5  28  60 131 222  64]\n",
      " [  8  23  25  69  84 301]]\n",
      "Accuracy: 57.94%\n"
     ]
    }
   ],
   "source": [
    "# Model SVM\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_sc, y_train)\n",
    "\n",
    "# Evaluasi\n",
    "y_pred = svm_model.predict(X_test_sc)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Akurasi Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving the XGBoost model from above in a pickle file for possible use later.\n",
    "svm_pickle = f\"model/svm_hog_lbp_model_acc_{accuracy}.pkl\"\n",
    "with open(svm_pickle, 'wb') as file:\n",
    "    pickle.dump(svm_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[449  22  12   9  10   8]\n",
      " [ 36 377  52  26   8  11]\n",
      " [ 33  79 244  73  45  36]\n",
      " [ 32  31 120 172  89  66]\n",
      " [  6  13  28  73 293  97]\n",
      " [ 16  15  28  26  64 361]]\n",
      "Accuracy: 61.96%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Membuat model Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "# Melatih model dengan data training\n",
    "rf_model.fit(X_train_sc, y_train)\n",
    "\n",
    "# Prediksi menggunakan model Random Forest\n",
    "y_pred = rf_model.predict(X_test_sc)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Akurasi Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving the XGBoost model from above in a pickle file for possible use later.\n",
    "svm_pickle = f\"model/rf_hog_lbp_model_acc_{accuracy}.pkl\"\n",
    "with open(svm_pickle, 'wb') as file:\n",
    "    pickle.dump(svm_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
