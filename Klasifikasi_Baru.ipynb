{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "from skimage.filters import gabor\n",
    "from skimage.transform import resize\n",
    "from skimage.util import img_as_ubyte\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recognition(image_path):\n",
    "    # Memuat Haar Cascade untuk deteksi wajah manusia atau kucing (Jika ada)\n",
    "    # cascade_wajah = cv.CascadeClassifier('/content/drive/MyDrive/PCVK_2024/Images/haarcascades/haarcascade_frontalface_default.xml')\n",
    "    cascade_wajah = cv2.CascadeClassifier('input_output/haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Membaca Gambar\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Mengubah gambar menjadi grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # scaleFactor: Faktor skala untuk memperkecil gambar setiap proses deteksi.\n",
    "    # minNeighbors: Jumlah minimum tetangga yang diperlukan untuk validasi objek.\n",
    "    # minSize: Ukuran minimum objek yang akan dideteksi.\n",
    "    faces = cascade_wajah.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Wajah tidak terdeteksi\n",
    "    if len(faces) == 0:\n",
    "        print(\"Wajah tidak terdeteksi!\")\n",
    "        return None\n",
    "\n",
    "    # Memproses setiap wajah yang terdeteksi\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Memotong gambar sesuai area deteksi wajah\n",
    "        face_crop = image[y:y+h, x:x+w]\n",
    "\n",
    "    return face_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekstraksi fitur HOG\n",
    "def extract_hog_features(img, size=(200, 200)):\n",
    "    img_resized = resize(img, size, anti_aliasing=True)\n",
    "    features, _ = hog(\n",
    "        img_resized, \n",
    "        orientations=9, \n",
    "        pixels_per_cell=(8, 8), \n",
    "        cells_per_block=(2, 2),\n",
    "        block_norm='L2-Hys', \n",
    "        visualize=True,\n",
    "        channel_axis=None\n",
    "    )\n",
    "    return features\n",
    "\n",
    "# Ekstraksi fitur LBP\n",
    "def extract_lbp_features(img, size=(200, 200)):\n",
    "    img_resized = cv2.resize(img, size)\n",
    "    img_resized = img_as_ubyte(img_resized)\n",
    "    radius = 1\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(img_resized, n_points, radius, method='uniform')\n",
    "    \n",
    "    hist, _ = np.histogram(\n",
    "        lbp.ravel(),\n",
    "        bins=np.arange(0, n_points + 3),\n",
    "        range=(0, n_points + 2)\n",
    "    )\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "    return hist\n",
    "\n",
    "# Ekstraksi fitur Gabor\n",
    "def extract_gabor_features(img, size=(200, 200)):\n",
    "    img_resized = resize(img, size, anti_aliasing=True)\n",
    "    filters = []\n",
    "    for theta in (0, np.pi / 4, np.pi / 2, 3 * np.pi / 4):  # Sudut orientasi\n",
    "        for frequency in (0.1, 0.2, 0.3):  # Frekuensi Gabor\n",
    "            real, _ = gabor(img_resized, frequency=frequency, theta=theta)\n",
    "            filters.append(np.mean(real))\n",
    "            filters.append(np.std(real))\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan semua fitur\n",
    "def extract_features_from_image(img_path, size=(200, 200)):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return np.array([])  # Jika gambar tidak valid, return array kosong\n",
    "    \n",
    "    # Ekstraksi fitur\n",
    "    hog_features = extract_hog_features(img, size)\n",
    "    lbp_features = extract_lbp_features(img, size)\n",
    "    gabor_features = extract_gabor_features(img, size)\n",
    "    \n",
    "    # Gabungkan semua fitur\n",
    "    return np.hstack([hog_features, lbp_features, gabor_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekstraksi fitur dari dataset\n",
    "def extract_features(image_path):\n",
    "    features = extract_features_from_image\n",
    "\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(image_path, model):\n",
    "    \"\"\"\n",
    "    Fungsi untuk mengklasifikasikan gambar menggunakan model yang telah dilatih.\n",
    "    \"\"\"\n",
    "    features = extract_features(image_path)\n",
    "\n",
    "    if features is None:\n",
    "        return \"Wajah tidak terdeteksi!\"\n",
    "\n",
    "    features = features.reshape(1, -1)\n",
    "    label = model.predict(features)[0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fungsi untuk menampilkan gambar dengan ukuran lebih kecil\n",
    "def display_image(image, title=\"Image\", figsize=(10, 10)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(cv2.cvtColor(image, cv.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 20770, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m model_xgb \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(model_path)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Evaluasi model dengan dataset test\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m accuracy, y_true, y_pred \u001b[38;5;241m=\u001b[39m evaluate_model(test_folder, model_xgb)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Tampilkan hasil\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAkurasi Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[20], line 30\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(folder_path, model)\u001b[0m\n\u001b[0;32m     27\u001b[0m true_label \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Prediksi dengan augmentasi dan tanpa augmentasi\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m predicted_label_original \u001b[38;5;241m=\u001b[39m classify_image(image_path, model)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# predicted_label_augmented = classify_image(image_path, model, augment=True)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Menambahkan hasil prediksi ke daftar\u001b[39;00m\n\u001b[0;32m     34\u001b[0m y_true\u001b[38;5;241m.\u001b[39mappend(true_label)\n",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m, in \u001b[0;36mclassify_image\u001b[1;34m(image_path, model)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWajah tidak terdeteksi!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m label \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(features)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m label\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1565\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1562\u001b[0m     iteration_range: Optional[IterationRange] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1563\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1564\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m-> 1565\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m   1566\u001b[0m             X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1567\u001b[0m             output_margin\u001b[38;5;241m=\u001b[39moutput_margin,\n\u001b[0;32m   1568\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1569\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1570\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[0;32m   1571\u001b[0m         )\n\u001b[0;32m   1572\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[0;32m   1573\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1574\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1186\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1186\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster()\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[0;32m   1187\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1188\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[0;32m   1189\u001b[0m             predict_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1190\u001b[0m             missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1191\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1192\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1193\u001b[0m         )\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[0;32m   1195\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2524\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2520\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2521\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2522\u001b[0m         )\n\u001b[0;32m   2523\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features() \u001b[38;5;241m!=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m-> 2524\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2525\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature shape mismatch, expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2526\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2527\u001b[0m         )\n\u001b[0;32m   2529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_np_array_like(data):\n\u001b[0;32m   2530\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ensure_np_dtype\n",
      "\u001b[1;31mValueError\u001b[0m: Feature shape mismatch, expected: 20770, got 1"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Fungsi untuk membaca dataset lokal dan menyiapkan filepath serta label\n",
    "def load_dataset(folder_path):\n",
    "    data = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                # Ekstrak label dari angka sebelum ekstensi\n",
    "                label = int(file_name.split('_')[-1].split('.')[0])\n",
    "                data.append((file_path, label))  # Path dan label\n",
    "    return pd.DataFrame(data, columns=['filepath', 'label'])\n",
    "\n",
    "# Fungsi untuk memproses dataset dan menghitung akurasi\n",
    "def evaluate_model(folder_path, model):\n",
    "    data = load_dataset(folder_path)\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        image_path = row['filepath']\n",
    "        true_label = row['label']\n",
    "\n",
    "        # Prediksi dengan augmentasi dan tanpa augmentasi\n",
    "        predicted_label_original = classify_image(image_path, model)\n",
    "        # predicted_label_augmented = classify_image(image_path, model, augment=True)\n",
    "\n",
    "        # Menambahkan hasil prediksi ke daftar\n",
    "        y_true.append(true_label)\n",
    "        y_pred.append(predicted_label_original)\n",
    "\n",
    "    # Hitung akurasi\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy, y_true, y_pred\n",
    "\n",
    "# Path dataset lokal\n",
    "train_folder = 'dataset/final_dataset/train'\n",
    "test_folder = 'dataset/final_dataset/test'\n",
    "\n",
    "# Memuat model\n",
    "model_path = \"model/xgboost_hog_lbp_model_acc_0.66.pkl\"\n",
    "model_xgb = joblib.load(model_path)\n",
    "\n",
    "# Evaluasi model dengan dataset test\n",
    "accuracy, y_true, y_pred = evaluate_model(test_folder, model_xgb)\n",
    "\n",
    "# Tampilkan hasil\n",
    "print(f\"Akurasi Model: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
